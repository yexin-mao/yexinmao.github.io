---
layout:            post
title:             "[Brief Reading Day 37] Momentum Contrast for Unsupervised Visual Representation Learning"
menutitle:         "[Brief Reading Day 37] Momentum Contrast for Unsupervised Visual Representation Learning"
date:              2022-05-01
category:          Blogs
author:            yexinmao
cover:             /assets/mountain-alternative-cover.jpg
tags:              Self-supervised Learning
---

[Paper Link](https://arxiv.org/pdf/1911.05722)

[Code Link](https://github.com/facebookresearch/moco)

This paper presents Momentum Contrast (MoCo) for unsupervised visual representation learning. From a perspective on contrastive learning as dictionary look-up, the authors build a dynamic dictionary with a queue and a moving-averaged encoder. This enables building a large and consistent dictionary on-the-fly that facilitates contrastive unsupervised learning.

Momentum Contrast (MoCo) trains a visual representation encoder by matching an encoded query q to a dictionary of encoded keys using a contrastive loss. The dictionary keys {k0,k1,k2,...} are defined on-the-fly by a set of data samples. The dictionary is built as a queue, with the current mini-batch enqueued and the oldest mini-batch dequeued, decoupling it from the mini-batch size. The keys are encoded by a slowly progressing encoder, driven by a momentum update with the query encoder. This method enables a large and consistent dictionary for learning visual representations.

MoCo provides competitive results under the common linear protocol on ImageNet classification. More importantly, the representations learned by MoCo transfers well to downstream tasks. MoCo can outperform its supervised pre-training counterpart in 7 detection/segmentation tasks on PASCAL VOC, COCO, and other datasets, sometimes surpassing it by large margins.
