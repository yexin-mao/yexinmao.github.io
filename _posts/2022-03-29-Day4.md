---
layout:            post
title:             "[Brief Reading Day 4] Deep Graph Infomax"
menutitle:         "[Brief Reading Day 4] Deep Graph Infomax"
date:              2022-03-29
category:          Graph
author:            yexinmao
cover:             /assets/mountain-alternative-cover.jpg
tags:              Graph Contrastive Learning
---

[Paper Link](https://arxiv.org/abs/1809.10341) 

[Code Link](https://github.com/PetarV-/DGI)

This paper presents Deep Graph Infomax (DGI) for learning unsupervised representations on graph-structured data. DGI relies on maximizing mutual information between patch representations and corresponding high-level summaries of graphs, both derived using established graph convolutional network architectures. The learnt patch representations summarize subgraphs centered around nodes of interest, and can thus be reused for downstream node-wise learning tasks. The overview of DGI in the single graph-setting is as follows:

1. Sample a negative example from the original graph by using the corruption function.
2. Obtain the patch representations for both the input graph and negative example by passing them through the encoder.
3. Summarize the input graph by passing its patch representations through the readout function.
4. Update parameters using gradient descent to update the objective function. 

By leveraging local mutual information maximization across the graphâ€™s patch representations, obtained by powerful graph convolutional architectures, DGI is able to obtain node embeddings that are mindful of the global structural properties of the graph. This enables competitive performance across a variety of both transductive and inductive classification tasks, at times even outperforming relevant supervised architectures.


