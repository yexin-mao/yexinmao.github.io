---
layout:            post
title:             "[Brief Reading Day 59] Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset"
menutitle:         "[Brief Reading Day 59] Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset"
date:              2022-05-23
category:          Video Understanding
author:            yexinmao
cover:             /assets/mountain-alternative-cover.jpg
tags:              Video Understanding
---

[Paper Link](https://arxiv.org/abs/1705.07750?context=cs)

[Code Link](https://github.com/hassony2/kinetics_i3d_pytorch)

This papar introduces a new dataset Kinetics, which has two orders of magnitude more data, with 400 human action classes and over 400 clips per
class, and is collected from realistic, challenging YouTube videos. It also introduce a new Two-Stream Inflated 3D ConvNet (I3D) that is based on 2D ConvNet inflation: filters and pooling kernels of very deep image classification ConvNets are expanded into 3D, making it possible to learn seamless spatio-temporal feature extractors from video while leveraging successful ImageNet architecture designs and even their parameters.

The techniques of I3D are as follows:

1. Inflating 2D ConvNets into 3D: This can be done by starting with a 2D architecture, and inflating all the filters and pooling kernels – endowing them with an additional temporal dimension. Filters are typically square and we just make them cubic – N × N filters become N × N × N.
2. Bootstrapping 3D filters from 2D Filters: This can be achieved, thanks to linearity, by repeating the weights of the 2D filters N times along the time dimension, and rescaling them by dividing by N. 

The architecture of I3D is composed of two networks with one I3D network trained on RGB inputs, and another on flow inputs which carry optimized, smooth flow information. The two networks trained separately and averaged their predictions at test time.

In the experiment, after pre-training on Kinetics, I3D models considerably improve upon the state-of-the-art in action classification, reaching 80.9% on HMDB-51 and 98.0% on UCF-101.

