---
layout:            post
title:             "[Brief Reading Day 56] An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
menutitle:         "[Brief Reading Day 56] An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
date:              2022-05-20
category:          Blogs
author:            yexinmao
cover:             /assets/mountain-alternative-cover.jpg
tags:              Visual Transformer
---

[Paper Link](https://arxiv.org/pdf/2010.11929.pdf)

[Code Link](https://github.com/google-research/vision_transformer)

This paper applies ViT, a pure transformer directly to sequences of image patches and shows that it can perform very well on image classification tasks. 
Moreover, when ViT is pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks, it attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.

In this model, we split an image into fixed-size patches, linearly embed each of them, add position embeddings, and feed the resulting sequence of vectors to a standard Transformer encoder. An extra learnable “classification token” is added to the sequence in order to perform classification.

This paper is the first to explore the direct application of Transformers to image recognition and achieves promising results. However, it does not apply ViT to other computer vision tasks, such as detection and segmentation. Also, the model is trained under the supervised setting and self-supervised pre-training methods should be explored.
