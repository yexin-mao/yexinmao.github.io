---
layout:            post
title:             "[Brief Reading Day 48] Learning without Forgetting"
menutitle:         "[Brief Reading Day 48] Learning without Forgetting"
date:              2022-08-07
category:          Incremental Learning
author:            yexinmao
cover:             /assets/mountain-alternative-cover.jpg
tags:              Incremental Learning
---

[Paper Link](https://arxiv.org/abs/1606.09282)

[Code Link](https://github.com/ngailapdi/LWF)

This paper proposes a method called "Learning without Forgetting" (LwF), which uses only new task data to train the network while preserving the original capabilities. 

In the framework of LwF, responses on each new task image are recorded firstly from the original network for outputs on the old tasks, which are the set of label probabilities for each training image in classification. Nodes for each new class are added to the output layer, fully connected to the layer beneath, with randomly initialized weights. When training, shared parameters θs and old task-specific parameters θo are firstly freezed that only new task-specific parameters θn are trained to convergence (warm-up step). Then, all weights θs, θo, and θn are jointly trained until convergence (joint-optimize step). The loss function is a triplet: For new tasks, the loss encourages predictions to be consistent with the ground truth. For each original task, the output probabilities for each image is made to be close to the recorded output from the original network, which uses the Knowledge Distillation loss. The regularization R corresponds to a simple weight decay of 0.0005.

Learning without Forgetting approach has several advantages:

1.Classification performance: Learning without Forgetting outperforms feature extraction and, more surprisingly, fine-tuning on the new task while greatly outperforming using fine-tuned parameters on the old task. Our method also generally perform better in experiments than alternatives at that time.
2.Computational efficiency: Training time is faster than joint training and only slightly slower than fine-tuning, and test time is faster than if one uses multiple fine-tuned networks for different tasks.
3.Simplicity in deployment: Once a task is learned, the training data does not need to be retained or reapplied to preserve performance in the adapting network.
