---
layout:            post
title:             "[Brief Reading Day 1] Bringing Your Own View: Graph Contrastive Learning without Prefabricated Data Augmentations"
menutitle:         "[Brief Reading Day 1] Bringing Your Own View: Graph Contrastive Learning without Prefabricated Data Augmentations"
date:              2022-03-26
category:          Blogs
author:            yexinmao
cover:             /assets/mountain-alternative-cover.jpg
tags:              Graph Contrastive Learning
---

[Paper Link](https://arxiv.org/abs/2201.01702)
[Code Link](https://github.com/Shen-Lab/GraphCL_Automated)


This paper targets more adaptive, automatic and generalizable graph contrastive learning by introducing a learnable prior, principles and a framework. Three questions are raised accordingly:

1. Space: How to represent the prior space of graph augmented views?
2. Principle: What principle can be relied upon to learn a prior in that space? 
3. Framework: What framework can be constructed to learn the prior in tandem with contrastive learning?

The answers to these questions are as follows: 

1. Space: The prefabricated discrete prior space is extended into a learnable continuous one parameterized by a graph generative model.
2. Principle: Information minimization (InfoMin) and information bottleneck (InfoBN) are used as principles to regularize the generator optimization and avoid collapsing to the trivial solution. 
3. Framework: The new framework is mathematically formulated as a bi-level optimization.

This new approach performs on par with the SOTA competitors on small benchmarks, and generalizes better on large-scale datasets, without resorting to human expertise of domain knowledge or tedious trial-and-error relying on downstream validation.

