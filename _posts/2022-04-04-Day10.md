---
layout:            post
title:             "[Brief Reading Day 10] Graph Contrastive Learning with Augmentations"
menutitle:         "[Brief Reading Day 10] Graph Contrastive Learning with Augmentations"
date:              2022-04-04
category:          Graph
author:            yexinmao
cover:             /assets/mountain-alternative-cover.jpg
tags:              Graph Contrastive Learning
---

[Paper Link](https://arxiv.org/pdf/2010.13902.pdf)

[Code Link](https://github.com/Shen-Lab/GraphCL)

This paper proposes a graph contrastive learning (GraphCL) framework for learning unsupervised representations of graph data. Four types of graph augmentations are designed to incorporate various underlying priors: 

1. Node dropping: Vertex missing does not alter semantics.
2. Edge perturbation: Semantic robustness against connectivity variations.
3. Attribute masking: Semantic robustness against losing partial attributes.
4. Subgraph: Local structure can hint the full semantics.

Observations show that:

1.Edge perturbation benefits social networks but hurts some biochemical molecules.
2.Applying attribute masking achieves better performance in denser graphs
3.Node dropping and subgraph are generally beneficial across datasets

This paper then systematically study the impact of various combinations of graph augmentations on multiple datasets, in four different settings: semi-supervised, unsupervised, and transfer learning as well as adversarial attacks. Experiment results verify the state-of-the-art performance of the proposed framework in both generalizability and robustness.

