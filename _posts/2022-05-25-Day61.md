---
layout:            post
title:             "[Brief Reading Day 61] Beyond Short Snippets: Deep Networks for Video Classification"
menutitle:         "[Brief Reading Day 61] Beyond Short Snippets: Deep Networks for Video Classification"
date:              2022-05-25
category:          Video Understanding
author:            yexinmao
cover:             /assets/mountain-alternative-cover.jpg
tags:              Video Understanding
---

[Paper Link](https://arxiv.org/abs/1503.08909?context=cs)

This paper proposes two methods capable of handling full length videos. The first method explores various convolutional temporal feature pooling architectures, examining the various design choices which need to be made when adapting a CNN for this task. The second proposed method explicitly models the video as an ordered sequence of frames. For this purpose the authors employ a recurrent neural network that uses Long Short-Term Memory (LSTM) cells which are connected to the output of the underlying CNN.

The different Feature-Pooling Architectures are: Conv Pooling, Late Pooling, Slow Pooling, Local Pooling, Time-Domain Pooling and GoogLenet Conv Pooling. 

The LSTM takes input the output from the final CNN layer at each consecutive video frame. CNN outputs are processed forward through time and upwards through five layers of stacked LSTMs. A softmax layer predicts the class at each time step. The parameters of the convolutional networks and softmax classifier are shared across time steps.

The best networks exhibit significant performance improvements over previously published results on the Sports 1 million dataset (73.1% vs. 60.9%) and the UCF-101 datasets with (88.6% vs. 88.0%) and without additional optical flow information (82.6% vs. 73.0%).

