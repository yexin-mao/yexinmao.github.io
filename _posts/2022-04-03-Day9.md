---
layout:            post
title:             "[Brief Reading Day 9] Node Representation Learning in Graph via Node-to-Neighbourhood Mutual Information Maximization"
menutitle:         "[Brief Reading Day 9] Node Representation Learning in Graph via Node-to-Neighbourhood Mutual Information Maximization"
date:              2022-04-03
category:          Blogs
author:            yexinmao
cover:             /assets/mountain-alternative-cover.jpg
tags:              Graph Contrastive Learning
---

[Paper Link](https://arxiv.org/abs/2203.12265)

[Code Link](https://github.com/dongwei156/n2n)

This paper proposes a simple-yet-effective MLP-based self-supervised node representation learning strategy with the idea of maximizing the mutual information between nodes and surrounding neighbourhood. The N2N mutual information maximization strategy essentially encourages graph smoothing by resorting to a quantifiable smoothness metric. The mutual information maximization problem is optimized by a surrogate contrastive loss. A scalable TAPS strategy is proposed which enables the positives to be selected upfront. In the case when only one positive is considered, expensive neighbourhood aggregation is avoided but still obtain satisfactory node classification performance.

Although this method also adopts mutual information maximization, however, differs from the previous contrastive methods from several perspectives:

1. Firstly, it avoids the operations such as graph augmentation, iterative aggregation and readout function by aligning nodes to their neighbourhood in the output layer of a MLP encoder. 
2. Secondly, instead of designing the pretext task heuristically, the framework can be theoretically justified by its connection to graph smoothing. 
4. Finally, a topology-aware sampling strategy is proposed in this work that converts the framework into highly efficient node-to-node contrastive learning but still maintains promising node classification performance.
